{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4bd825-edbe-4c22-a5f8-847ec26fe45a",
   "metadata": {
    "init_cell": true,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.warn {    \n",
       "    background-color: #FDEDEC;\n",
       "    border-color: #E74C3C;\n",
       "    border-left: 5px solid #E74C3C;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.task {    \n",
       "    background-color: #EBF5FB;\n",
       "    border-color: #2E86C1;\n",
       "    border-left: 5px solid #2E86C1;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.expert {    \n",
       "    background-color: #F4ECF7;\n",
       "    border-color: #6C3483;\n",
       "    border-left: 5px solid #6C3483;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.solution {    \n",
       "    background-color: #EAFAF1;\n",
       "    border-color: #2ECC71;\n",
       "    border-left: 5px solid #2ECC71;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.summary {    \n",
       "    background-color: #FCF3CF;\n",
       "    border-color: #F1C40F;\n",
       "    border-left: 5px solid #F1C40F;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "hr.dashed {\n",
       "    border: 0;\n",
       "    border-bottom: 1px dashed #ccc;\n",
       "    background: #999;\n",
       "}\n",
       "\n",
       "hr.double {\n",
       "    overflow: visible; /* For IE */\n",
       "    padding: 0;\n",
       "    border: none;\n",
       "    border-top: medium double #333;\n",
       "    color: #333;\n",
       "    text-align: center;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just getting some formatting information and is not part of the tasksheet!\n",
    "from IPython.core.display import HTML\n",
    "import urllib.request\n",
    "def start_css():\n",
    "    with urllib.request.urlopen('https://github.com/uolphysicsteaching/resources/raw/main/notebook.css') as response:\n",
    "        return HTML(response.read().decode(\"utf-8\"))\n",
    "start_css()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be2e03-cf8b-4836-b77c-ab235cae7b2e",
   "metadata": {},
   "source": [
    "# PHYS2320 Computing 2 Lab 6 Worksheet\n",
    "\n",
    "This worksheet can be viewed as a pdf, html page or as a JuPyter Notebook. If you are using the notebook version then you can work through the worksheet and add your code to it.\n",
    "\n",
    "You will find it in the **Workshop 6 - Week 11** folder on the **Semester 1 Workshops** Area in the PHYS2320 Minerva pages. There are three versions, pdf, html and notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0746608-05cf-4a4c-804d-9571705a999a",
   "metadata": {},
   "source": [
    "## Aims\n",
    "\n",
    "This lab's aims are\n",
    "\n",
    " - Introduction to the Pandas library for dealing with tables of mixed data\n",
    " - Create and do simple manipulations of DataFrames\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "This worksheet is best viewed in JuPyter Notebook. If you have installed anaconda python on your own computer, or are using the virtual Windows desktop, then you probably have JuPyter Notebook already install. If you are using Windows, then there should be a menu entry in your start menu, on a Mac you may need to open a terminal window and type:\n",
    "\n",
    "> jupyter notebook\n",
    "\n",
    "### Attendance Records\n",
    "\n",
    "<div class=\"warn\">\n",
    "\n",
    "Do not forget to register your attendance at a Computer Labs session! <https://phys2320.leeds.ac.uk/attendance/register>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f402ba2b-65b5-49cd-ba20-5d55f607b0f2",
   "metadata": {},
   "source": [
    "# Pandas - A Python library for working with real-world data\n",
    "\n",
    "Following on the heals of the internet revolution has been the rise of data-science and big data. The routine collection of vast quantities of information and the ability to store and access it almost instantaneously has lead to the need to process and analyze it to see trends and correlations and to visualize and present it in ways that humans can handle. Python is one of the leading tools for data science thanks in no small part to its powerful libraries such as numpy and scipy.\n",
    "\n",
    "Although numpy is excellent for working with purely numerical data, in many real world applications datasets tend to be a mixture of text and numbers. On the other hand, in many situations we think about tables of data where each row represents a set of information about one item, with the columns holding the same category of information about each item - this is the sort of typical use of a spreadsheet.\n",
    "\n",
    "Spreadsheet programs such as Excel tend to get unwieldy when dealing with hundreds of thousands or millions of rows of data, or when the analysis functions that need to be used are complex and this is where Python and in particular the [Pandas](https://pandas.pydata.org/) library is the tool of choice.\n",
    "\n",
    "## Starting with Pandas\n",
    "\n",
    "Pandas is installed as standard on Anaconda Python - the usual way to import it is with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f78a3-5cc7-49e7-9f9f-d3d1027d0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Also include some standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741a180-af32-4678-94f8-65c0d8af9ddb",
   "metadata": {},
   "source": [
    "### Pandas DataFrames\n",
    "\n",
    "The **DataFrame** is to pandas what the **array** is to numpy - it is the most commonly used data-structure and the heart of the library. A DataFrame is a bit like a 2D array, except that:\n",
    "- Each column can store a different *type* of data - it doesn't have to just be numbers\n",
    "- Columns normally have *names* so you can refer to them by their name rather than am integer index\n",
    "- You can assign one column to be the *index* for the rows and then refer to rows by the value of that column - in essence you are giving a name to each row as well as each column.\n",
    "- Pandas provides a wide range of functions to analyse and manipulate and plot the data in a DataFrame.\n",
    "- It's also possible to convert the columns of data to numpy arrays - pandas is designed to work closely with numpy.\n",
    "\n",
    "There are many different ways to create DataFrames - we'll see more later, but to start with we can create one from a list of dictionaries:\n",
    "(data taken from [https://www.kaggle.com/dannielr/marvel-superheroes/version/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23862438-afcf-42e2-9c53-989f52478b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heros=[ {'Alignment': 'good', 'Combat': 100, 'Durability': 42, 'Intelligence': 100, 'Name': 'Batman', 'Power': 37, 'Speed': 27, 'Strength': 18},\n",
    "  {'Alignment': 'good', 'Combat': 75, 'Durability': 30, 'Intelligence': 75, 'Name': 'Storm', 'Power': 88, 'Speed': 47, 'Strength': 10},\n",
    "  {'Alignment': 'good', 'Combat': 100, 'Durability': 56, 'Intelligence': 63, 'Name': 'Captain America', 'Power': 46, 'Speed': 35, 'Strength': 19},\n",
    "  {'Alignment': 'good', 'Combat': 64, 'Durability': 70, 'Intelligence': 75, 'Name': 'Groot', 'Power': 92, 'Speed': 33, 'Strength': 85},\n",
    "  {'Alignment': 'good', 'Combat': 64, 'Durability': 85, 'Intelligence': 100, 'Name': 'Iron Man', 'Power': 100, 'Speed': 58, 'Strength': 85},\n",
    "  {'Alignment': 'good', 'Combat': 100, 'Durability': 32, 'Intelligence': 75, 'Name': 'Black Widow', 'Power': 32, 'Speed': 27, 'Strength': 13}]\n",
    "\n",
    "hero_df=pd.DataFrame(heros)\n",
    "hero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49748d9-780a-41ec-93db-19a2a0917e96",
   "metadata": {},
   "source": [
    "You can see that pandas gives each column a heading - and we will see below that we can refer to each column by name. It also numbers the rows for us - by default it simply jsut numbers the rows from 0 onward, but we will also see how we can control this.\n",
    "\n",
    "Pandas views the `DataFrame` as being a collection of columns - which it calls a `Series`. A `Series` is a 1D array of data whilst a `DataFrame` is a 2D array of data except the different `Series` in the `DataFrame` can have different data types. Pandas looks after all the details of this, and most of the time you don't need to worry about the details.\n",
    "\n",
    "The `DataFrame.describe()` function can give us some quick statistics about the numerical data in our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f119a-4dbd-4785-a524-34dd2d925307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hero_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336abaf0-e0e1-4e88-aaae-866430c3edf3",
   "metadata": {},
   "source": [
    "### Selecting Columns and Rows\n",
    "\n",
    "In this example we have relatively few columns and can see them in the notebook all at once. If we have lots of columns we can use the `DataFrame.columns` attribute to get a list of all the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab533e-7b36-49da-a3c6-f6037b2bbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31348dc5-9fb5-4b91-ae89-e547753c45b4",
   "metadata": {},
   "source": [
    "To access the information in just a single column, we can treat the `DataFrame` like a dictionary where the column names are the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e25e77-7471-4c40-aafc-dea812de4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df[\"Intelligence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e13bf-8083-477b-a734-8bfe0c5ef565",
   "metadata": {},
   "source": [
    "As a short cut, for columns that are also valid Python names, we can access them like an `attribute` with the 'dot' syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bb4ae-f54b-40c3-a5fa-fbe87cb85843",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51834684-86fb-413f-8750-e7d1278669ef",
   "metadata": {},
   "source": [
    "To access data by row, we need to use the `DataFrame.loc` (location) attribute. This is something we can index and it will return rows - the indexing rules are basically the same as numpy's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d63f3-e99a-4879-9b1d-330f94ed752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b6ffc-870a-4052-9448-f3bacaf95de8",
   "metadata": {},
   "source": [
    "To get one particular cell, we can index `DataFrame.loc` with both a row and a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c675ba-1390-44eb-9141-16275c620c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.loc[0,\"Intelligence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e15976-84b0-46f5-a927-149c745785cf",
   "metadata": {},
   "source": [
    "### Defining an index for the rows\n",
    "\n",
    "Using numbers to index the row is not perhaps the most natural thing to do when the data has a set of names in one column - so we can tell Pandas that the DataFrame should use the Name column to identify rows. To do this we use `DataFrame.set_index()`.\n",
    "\n",
    "Note, by default, Pandas will always make a new copy of the DataFrame with whatever change you have requested. This can require huge amounts of memory if your data set is large - so you add an `inplace=True` keyword argument to make it change the original DataFrame instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6400b-689c-4791-ba47-fd214995510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df=hero_df.set_index(\"Name\")\n",
    "hero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d04750-3545-4c59-9525-ee1d063bdfc3",
   "metadata": {},
   "source": [
    "Now we can refer to our superheroes by name to get information about them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e21e48-b139-41c3-8d9e-2de3e41ce92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.loc[\"Groot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d96a1b-6a7f-4504-913c-8ccb832e5a62",
   "metadata": {},
   "source": [
    "### Analysing the contents of a DataFrame\n",
    "\n",
    "Many of the numpy functions have equivalents in pandas. For example, `argmin()` will tell us the row which has the minimum value of a particular column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c12f1-0c55-4807-b686-d36d9db52446",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.Intelligence.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb559ce4-e302-4b08-9247-1783c47364cf",
   "metadata": {},
   "source": [
    "We can now use this to identify which superhero is most lacking in the brain power department!\n",
    "\n",
    "Probably the easiest thing to do is to use this result with the `DataFrame.index` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5f9ec-0d62-46f1-85ef-fde478c29af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.index[hero_df.Intelligence.argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3931f-1dc4-4acc-8bc8-bd0e2af89eea",
   "metadata": {},
   "source": [
    "Alternatively, since we've now told Pandas to use the `Name` column in the index that `DataFrame.loc` uses, we cannot provide numbers to the `.loc` attribute - we need to use another `DataFrame` attribute to index rows with numbers - `DataFrame.iloc` (Integer-Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16be87-e5d0-4015-9fe0-cf435c22cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.iloc[hero_df.Intelligence.argmin()].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad85510-8abf-4bb9-adfc-aebbbeaa86af",
   "metadata": {},
   "source": [
    "You can also use a `Series` or `DataFrame` directly with many `numpy` and `scipy` functions - but you need to remember that a `DataFrame` might contain data other than numbers and so `numpy` may not understand it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688fc5a-419f-4c5f-a49f-71a05244f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(hero_df.Speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85446e6-52a6-470a-88d5-547470dedfb4",
   "metadata": {},
   "source": [
    "We can use a list of column names to build a subset of the columns in our original `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442730f9-7ba4-463e-a166-c712c0064eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df[[\"Combat\",\"Durability\",\"Intelligence\",\"Power\",\"Speed\",\"Strength\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892d40e-005a-4b6d-b4bb-70492779bd41",
   "metadata": {},
   "source": [
    "If we need to just get the numbers as an array, that can be done with the `DataFrame.to_numpy()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bdc22-fcff-4faf-9657-e973e93d5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=hero_df[[\"Combat\",\"Durability\",\"Intelligence\",\"Power\",\"Speed\",\"Strength\"]]\n",
    "scores.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757859a-0817-437e-b51a-02c711099898",
   "metadata": {},
   "source": [
    "Alternatively the `.values` attribute will give us the same underlying data as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597e7b4-4608-404f-81be-29e6591f2e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f9aa2-0c63-4986-97c1-813d93c4b3ea",
   "metadata": {},
   "source": [
    "And now we can sum the rows of this DataFrame, just as we would with a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec9186-3a55-4dd2-8469-7867923c1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.values.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603cf20-90f0-46fc-a858-986b06ddab31",
   "metadata": {},
   "source": [
    "But often going to numpy isn't necessary and it can be beneficial not to lose the index...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0004477-cf3d-4b19-a0a4-528bddd965f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c75686-b35b-4f85-a793-126801842568",
   "metadata": {},
   "source": [
    "### Adding Data to the DataFrame\n",
    "\n",
    "If we want to add this data into the `DataFrame` we can do that easily by simply assing the new column the values- treating the `DataFrame` just like it was a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d9f64-523b-4142-b8bf-a017b446575e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hero_df[\"Total\"]=scores.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7976fb-16a6-4611-9232-f963924a2d2a",
   "metadata": {},
   "source": [
    "Of course, now we'd like to sort our heroes by their total score - and this is easily done with the `DataFrame.sort_values()` function - note that we use the `inplace=True` to avoid duplicating our data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b196a0f-cf5d-4deb-95bc-a5ee47153e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.sort_values(\"Total\", inplace=True)\n",
    "hero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981d417-df0a-42aa-b698-2b560eb210f5",
   "metadata": {},
   "source": [
    "This is a very small dataset, but with datasets that have many (millions!) of rows, you wouldn't want to try and display every row - so one could use the `DataFrame.head()` and `DataFrame.tail()` functions to limit the number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cca1d0-6176-482f-b646-49d052e653ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937386ef-f17b-4786-9afc-08a78b6ec10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c691bdb-02f4-4126-af15-8344335e4452",
   "metadata": {},
   "source": [
    "### Saving a DataFrame\n",
    "\n",
    "Having done our analysis, one of the nicest things about Pandas is that it can save `DataFrames` to a wide variety of formats - including Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cf30d-30a9-42fb-884b-b1d920aa36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_df.to_excel(\"Heros.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5922d-f4cb-4992-aae6-bc1cddba5ad4",
   "metadata": {},
   "source": [
    "`pandas` supports saving to a wide variety of formats - common examples are to csv files, to json files (particularly in web applications) and directly to databases as well as to Excel files.\n",
    "\n",
    "### Data Visualization\n",
    "\n",
    "Finally, we might wajnt to visualize our data - Pandas provides a basic visualization function in `DataFrame.plot()` that generally tries to do something sensible with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b701732-60e2-46de-8f17-07bbdd9909e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hero_df.plot(kind=\"bar\",y=[\"Combat\",\"Durability\",\"Intelligence\",\"Speed\",\"Strength\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabee12e-545b-48eb-98cb-a0d4bd6d0f56",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "Fun though it is to work with Marvel Superhero data, for the remainder of this session we will use some more scientific data. You will probably want to consult both the padnas documentation on its [website](https://pandas.pydata.org/docs/) as well as the sumary above. Pandas is a big library and it's not possible to give a comprehensive tutorial in a single lab session, but it is well documented and has a large number of users.\n",
    "\n",
    "## Task 1\n",
    "\n",
    "<div class=\"task\">\n",
    "    \n",
    "The first task will be to download some data about the periodic table from github. The file you need is located at:\n",
    "    \n",
    "<a href=\"https://github.com/andrejewski/periodic-table/raw/master/data.json\">https://github.com/andrejewski/periodic-table/raw/master/data.json</a>\n",
    "    \n",
    "The data is stored in JSON format - a common format used for exchanging information on the web as it is easily readable by JavaScript. Fortunately pandas can also read this format, and even more conveniently, can read it directly from the internet!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b9e88-e5c7-410b-8408-90f915202d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table=pd.read_json(\"https://github.com/andrejewski/periodic-table/raw/master/data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f7bc0-f4b2-4fa7-99cd-ecb472aa1cae",
   "metadata": {},
   "source": [
    "<div class=\"task\">\n",
    "<ol>\n",
    "    <li>Set the index of the data frame to be the chemical symbol of the element</li>\n",
    "    <li>Identify the most electronegative and least electronegative element in the data set<br/>\n",
    "        <b>NB</b>Some of the data has missing values and in the original data this is represented by an empty string ''. I will be easier to work with the data if you replace the empty strings with `np.NaN` (not a number) values.Look up DataFrame.replace() to see how to do this.</li>\n",
    "    <li>Make a plot of atomic radius against atomic number.</li>\n",
    "    <li>Create a new data frame of the metallic elements and determine how many there are.</li>\n",
    "    <li>Sort the metals by order of the year of discovery<br/>\n",
    "        <b>NB</b>You can replace the \"Ancient\" years with the year 0.</li>\n",
    " </ol>\n",
    " </div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73921643-4836-46dd-ba70-16fd0de66063",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "A really common thing that one needs to do in Data Science is to combine information from a number of different sources. In this example, we will combine the information from the web about elements in the periodic table with some data we have about superconductors.\n",
    "\n",
    "<div class=\"task\">\n",
    "    <p>The file <i>Superconductors.xlsx</i> that was in the same folder on Minerva as the task sheet has some data about various superconductors.The aim of this task is to combine the data in this file with the periodic table data to be able to correlate the superconducting properties with the element properties.<p>\n",
    "    <ol>\n",
    "        <li>Download the file and read it into a new pandas data frame.</li>\n",
    "        <li>Inspect the columns and set the index to be the column with the chemical formula.</li>\n",
    "        <li>Keep only those superconductors that are elements in the periodic table and make a new DataFrame that combines the information about the superconducting elements.<br/>\n",
    "            To do this you will need to do several steps:\n",
    "            <ol>\n",
    "                <li>Some elements have more than one phase that superconducts and so have two rows with the same chemical symbol. The `DataFrame.index.duplicated` will show which rows have a duplicate index. You can then invert this with the ~ operator and use that with the `DataFrame.loc` location to select non-duplicate element rows.</li>\n",
    "               <li> The `pd.concat` function can be used to join two DataFrames together - it will pay attention to the row labels and column names to match the rows or columns between the two data frames. You can give it an <i>axis=</i> parameter to tell it to joint he dataframes by row or columns.</li>\n",
    "    </ol>\n",
    "            <li>Make a pliots of the atomic number versus critical temperature T_C and the critical field H_C versus T_C.</li>\n",
    "        <li>Finally, save the combined dataset to an Excel spreadsheet file and chedck you can open it in Excel.</li>\n",
    "    </ol>\n",
    "           \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd96661-1547-458e-aada-329dffd66a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
